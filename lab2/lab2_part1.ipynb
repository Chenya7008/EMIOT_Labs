{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Manipulations and Image Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import color\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an image\n",
    "original_image = Image.open(\"./test_images/100007.jpg\")\n",
    "\n",
    "# Show the image\n",
    "original_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the image to numpy array to manipulate it\n",
    "image_array = np.array(original_image)\n",
    "\n",
    "# Inspect the image array\n",
    "print(f\"Shape: {image_array.shape}\")\n",
    "print(f\"Red channel:\\n{image_array[:, :, 0]}\")\n",
    "print(f\"Green channel:\\n{image_array[:, :, 1]}\")\n",
    "print(f\"Blue channel:\\n{image_array[:, :, 2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation example: make the image darker\n",
    "image_array_v1 = (image_array * 0.6).astype(np.uint8)\n",
    "image_v1_darker = Image.fromarray(image_array_v1)\n",
    "image_v1_darker.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation example: manipulate the red channel\n",
    "image_array_v2 = image_array[:, :, 0]\n",
    "image_v2 = Image.fromarray(image_array_v2)\n",
    "image_v2.show()\n",
    "# Why is it grey?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_array_v2 = image_array.copy()\n",
    "image_array_v2[:, :, 1] = 0  # Set green channel to 0\n",
    "image_array_v2[:, :, 2] = 0  # Set blue channel to 0\n",
    "image_v2 = Image.fromarray(image_array_v2)\n",
    "image_v2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform RGB array to Lab array\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "image_array_lab = rgb2lab(image_array)\n",
    "# Inspect the image array\n",
    "print(f\"Shape: {image_array_lab.shape}\")\n",
    "print(f\"L channel:\\n{image_array_lab[:, :, 0]}\")\n",
    "print(f\"a channel:\\n{image_array_lab[:, :, 1]}\")\n",
    "print(f\"b channel:\\n{image_array_lab[:, :, 2]}\")\n",
    "\n",
    "# Transform Lab array to RGB array\n",
    "image_array_rgb = lab2rgb(image_array_lab)\n",
    "\n",
    "# Inspect the image array\n",
    "print(f\"Shape: {image_array_rgb.shape}\")\n",
    "print(f\"Red channel:\\n{image_array_rgb[:, :, 0]}\")\n",
    "print(f\"Green channel:\\n{image_array_rgb[:, :, 1]}\")\n",
    "print(f\"Blue channel:\\n{image_array_rgb[:, :, 2]}\")\n",
    "\n",
    "# Show the image\n",
    "image = Image.fromarray((image_array_rgb * 255).astype(np.uint8))\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform RGB to HSV\n",
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "\n",
    "image_array_hsv = rgb2hsv(image_array)\n",
    "# Inspect the image array\n",
    "print(f\"Shape: {image_array_hsv.shape}\")\n",
    "print(f\"H channel:\\n{image_array_hsv[:, :, 0]}\")\n",
    "print(f\"S channel:\\n{image_array_hsv[:, :, 1]}\")\n",
    "print(f\"V channel:\\n{image_array_hsv[:, :, 2]}\")\n",
    "\n",
    "# Histogram equalization on the V channel\n",
    "from skimage.exposure import equalize_hist\n",
    "\n",
    "image_array_hsv[:, :, 2] = equalize_hist(image_array_hsv[:, :, 2])\n",
    "print(f\"V channel after equalization:\\n{image_array_hsv[:, :, 2]}\")\n",
    "\n",
    "# Transform HSV to RGB\n",
    "image_array_rgb = hsv2rgb(image_array_hsv)\n",
    "\n",
    "# Show the image\n",
    "image = Image.fromarray((image_array_rgb * 255).astype(np.uint8))\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power(image):\n",
    "    img = image.astype(np.float64)\n",
    "    gamma = 0.7755\n",
    "    w0 = 1.48169521e-6\n",
    "    w_r = 2.13636845e-7\n",
    "    w_g = 1.77746705e-7\n",
    "    w_b = 2.14348309e-7\n",
    "    \n",
    "    r_pow = w_r * np.power(img[:, :, 0], gamma)\n",
    "    g_pow = w_g * np.power(img[:, :, 1], gamma)\n",
    "    b_pow = w_b * np.power(img[:, :, 2], gamma)\n",
    "    \n",
    "    return w0 + np.sum(r_pow + g_pow + b_pow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distortion(original_img,modified_img):\n",
    "    if original_img.shape != modified_img.shape:\n",
    "        original_img = original_img[:,:,:3]\n",
    "        modified_img = modified_img[:,:,:3]\n",
    "\n",
    "    lab_orig = color.rgb2lab(original_img)\n",
    "    lab_mod = color.rgb2lab(modified_img)\n",
    "    \n",
    "    diff = lab_orig - lab_mod\n",
    "    dist_pixel = np.sqrt(np.sum(np.square(diff), axis=2))\n",
    "    total_error = np.sum(dist_pixel)\n",
    "    \n",
    "    h, w, _ = original_img.shape\n",
    "    max_dist = np.sqrt(100**2 + 255**2 + 255**2)\n",
    "    \n",
    "    return (total_error / (h * w * max_dist)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "power_result_original=compute_power(np.array(original_image))\n",
    "power_result_v1=compute_power(np.array(image_v1_darker))\n",
    "distortion_result=compute_distortion(np.array(original_image),np.array(image_v1_darker))\n",
    "\n",
    "print(power_result_original)\n",
    "print(power_result_v1)\n",
    "print(distortion_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#professor provides\n",
    "from typing import Tuple\n",
    "\n",
    "def displayed_image(\n",
    "        i_cell: np.ndarray,\n",
    "        vdd: float,\n",
    "        p1: float = 4.251e-5,\n",
    "        p2: float = -3.029e-4,\n",
    "        p3: float = 3.024e-5,\n",
    "        orig_vdd: float = 15,\n",
    "        ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Display an image on the OLED display taking into account the effect of DVS.\n",
    "\n",
    "    :param i_cell: An array of the currents drawn by each pixel of the display.\n",
    "    :param vdd: The new voltage of the display.\n",
    "    \"\"\"\n",
    "    i_cell_max = (p1 * vdd * 1) + (p2 * 1) + p3\n",
    "    image_rgb_max = (i_cell_max - p3) / (p1 * orig_vdd + p2) * 255\n",
    "    out = np.round((i_cell - p3) / (p1 * orig_vdd + p2) * 255)\n",
    "    original_image = out.copy()\n",
    "\n",
    "    # Clip the values exceeding `i_cell_max` to `image_rgb_max`\n",
    "    out[i_cell > i_cell_max] = image_rgb_max\n",
    "\n",
    "    return original_image.astype(np.uint8), out.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#professor provides\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load the .mat file\n",
    "mat_data = loadmat('sample_cell_current.mat')[\"I_cell_sample\"]\n",
    "\n",
    "# Inspect the loaded data\n",
    "print(f\"Shape: {mat_data.shape}\")\n",
    "print(f\"Red channel:\\n{mat_data[:, :, 0]}\")\n",
    "print(f\"Green channel:\\n{mat_data[:, :, 1]}\")\n",
    "print(f\"Blue channel:\\n{mat_data[:, :, 2]}\")\n",
    "\n",
    "image_array_orig, image_array_w_dvs = displayed_image(mat_data, 10)\n",
    "image_orig = Image.fromarray(image_array_orig)\n",
    "image_orig.show()\n",
    "image_w_dvs = Image.fromarray(image_array_w_dvs)\n",
    "image_w_dvs.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_power_part1(img):\n",
    "    return compute_power(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hungry_blue(img, k):\n",
    "    img_mod = img.astype(np.int16) #default uint8[0,255] underflow\n",
    "    img_mod[:, :, 2] = img_mod[:, :, 2] - k\n",
    "    img_mod = np.clip(img_mod, 0, 255) \n",
    "    return img_mod.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images function\n",
    "def load_images_from_folder(folder_path, limit=50):\n",
    "    images_list = []\n",
    "    \n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "    \n",
    "    try:\n",
    "        filenames = os.listdir(folder_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: folder '{folder_path}'\")\n",
    "        return []\n",
    "\n",
    "    filenames.sort()\n",
    "\n",
    "    count = 0\n",
    "    print(f\"Loading images from {folder_path}...\")\n",
    "\n",
    "    for filename in filenames:\n",
    "        if count >= limit:\n",
    "            break\n",
    "        \n",
    "        if filename.lower().endswith(valid_extensions):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    img_rgb = img.convert('RGB')\n",
    "                    \n",
    "                    img_array = np.array(img_rgb)\n",
    "                    \n",
    "                    images_list.append(img_array)\n",
    "                    count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load image {filename}: {e}\")\n",
    "\n",
    "    print(f\"Loaded {len(images_list)} images successfully.\")\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from the specified folder\n",
    "# 3 groups of images: 50 test images, 5 screen images, and all together\n",
    "my_folder_path=\"./test_images\"\n",
    "images = load_images_from_folder(my_folder_path, limit=50)\n",
    "screen_folder_path=\"./myscreen\"\n",
    "screen_images = load_images_from_folder(screen_folder_path, limit=5)\n",
    "\n",
    "all_images = images + screen_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hungry blue pareto curves\n",
    "#compare the two groups of images (natural vs. screenshots) in terms of distortion and power saving for different k values\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the k value range to test\n",
    "k_values = range(0, 256, 10) \n",
    "\n",
    "def run_hungry_blue_experiment(image_list):\n",
    "    \"\"\"General function: run Hungry Blue on a set of images and return average statistics\"\"\"\n",
    "    avg_results = []\n",
    "    for k in k_values:\n",
    "        savings = []\n",
    "        distortions = []\n",
    "        for img in image_list:\n",
    "            # 1. Compute original power\n",
    "            p_orig = estimate_power_part1(img)\n",
    "            # 2. Apply transformation\n",
    "            img_new = apply_hungry_blue(img, k)\n",
    "            # 3. Compute new power and distortion\n",
    "            p_new = estimate_power_part1(img_new)\n",
    "            dist = compute_distortion(img, img_new)\n",
    "            # 4. Record energy saving rate\n",
    "            savings.append((p_orig - p_new) / p_orig * 100 if p_orig > 0 else 0)\n",
    "            distortions.append(dist)\n",
    "        # Return average (distortion, saving) for this k value\n",
    "        avg_results.append((np.mean(distortions), np.mean(savings)))\n",
    "    return avg_results\n",
    "\n",
    "# --- Run experiments on each group separately ---\n",
    "print(\"Processing natural image group (50 images)...\")\n",
    "results_natural = run_hungry_blue_experiment(images)\n",
    "\n",
    "print(\"Processing screenshot group (5 images)...\")\n",
    "results_screenshots = run_hungry_blue_experiment(screen_images)\n",
    "\n",
    "# --- Visualize comparison ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# --- Plot natural image group ---\n",
    "x_nat = [r[0] for r in results_natural]\n",
    "y_nat = [r[1] for r in results_natural]\n",
    "plt.plot(x_nat, y_nat, 'b-o', label='Natural Images')\n",
    "\n",
    "# Label points for natural image group\n",
    "for i, k in enumerate(k_values):\n",
    "    plt.text(x_nat[i], y_nat[i] + 0.5, f'k={k}', color='blue', fontsize=9, ha='center')\n",
    "\n",
    "# --- Plot screenshot group ---\n",
    "x_scr = [r[0] for r in results_screenshots]\n",
    "y_scr = [r[1] for r in results_screenshots]\n",
    "plt.plot(x_scr, y_scr, 'r--s', label='Screenshots')\n",
    "\n",
    "# Label points for screenshot group\n",
    "for i, k in enumerate(k_values):\n",
    "    plt.text(x_scr[i], y_scr[i] + 0.5, f'k={k}', color='red', fontsize=9, ha='center')\n",
    "\n",
    "plt.title('Hungry Blue: Impact of Parameter k on Natural vs. Screenshots')\n",
    "plt.xlabel('Average Distortion (%)')\n",
    "plt.ylabel('Average Power Saving (%)')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further compare the two groups by separating screenshots into white and black backgrounds\n",
    "\n",
    "white_screens = [screen_images[0], screen_images[2]]\n",
    "black_screens = [screen_images[1], screen_images[3], screen_images[4]]\n",
    "\n",
    "print(\"Computing white background screenshots...\")\n",
    "results_white = run_hungry_blue_experiment(white_screens)\n",
    "\n",
    "print(\"Computing black background screenshots...\")\n",
    "results_black = run_hungry_blue_experiment(black_screens)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([r[0] for r in results_white], [r[1] for r in results_white], 'r-o', label='White Background (Light Mode)')\n",
    "plt.plot([r[0] for r in results_black], [r[1] for r in results_black], 'k-s', label='Black Background (Dark Mode)')\n",
    "plt.plot([r[0] for r in results_natural], [r[1] for r in results_natural], 'b--', label='Natural Images')\n",
    "\n",
    "plt.title('Impact of Background Color on Power Saving (Hungry Blue)')\n",
    "plt.xlabel('Average Distortion (%)')\n",
    "plt.ylabel('Average Power Saving (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build per-image detailed data for Hungry Blue, stored in detailed_data\n",
    "detailed_data = {}\n",
    "\n",
    "for k in k_values:\n",
    "    current_k_stats = []\n",
    "    for idx, img in enumerate(all_images):\n",
    "        p_orig = estimate_power_part1(img)\n",
    "        img_new = apply_hungry_blue(img, k)\n",
    "        p_new = estimate_power_part1(img_new)\n",
    "        saving = (p_orig - p_new) / p_orig * 100 if p_orig > 0 else 0\n",
    "        dist = compute_distortion(img, img_new)\n",
    "        current_k_stats.append({'idx': idx, 'saving': saving, 'dist': dist})\n",
    "    detailed_data[k] = current_k_stats\n",
    "\n",
    "print(f\"detailed_data built: {len(detailed_data)} k values, {len(next(iter(detailed_data.values())))} images each\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_simplified_analysis(k, stats, images):\n",
    "    # Filter out-of-range idx\n",
    "    valid_stats = [s for s in stats if s['idx'] < len(images)]\n",
    "    \n",
    "    if not valid_stats:\n",
    "        print(\"Error: no idx in the input data matches the current image list!\")\n",
    "        return\n",
    "\n",
    "    # Select extreme values as representative examples\n",
    "    min_dist = min(valid_stats, key=lambda x: x['dist'])\n",
    "    max_dist = max(valid_stats, key=lambda x: x['dist'])\n",
    "    cases = [('MIN Distortion', min_dist, '#2ca02c'), \n",
    "             ('MAX Distortion', max_dist, '#ff7f0e')]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle(f'Hungry Blue Distortion Analysis: k = {k} ', fontsize=22, fontweight='bold', y=0.98)\n",
    "\n",
    "    col_titles = ['Original Image', 'Processed (−B)', 'Power Contrib (RGB Mean)']\n",
    "    for ci, ct in enumerate(col_titles):\n",
    "        axes[0, ci].set_title(ct, fontsize=16, fontweight='bold', pad=15)\n",
    "\n",
    "    for row, (label, stat, color_code) in enumerate(cases):\n",
    "        idx = stat['idx']\n",
    "        img_orig = images[idx]\n",
    "        \n",
    "        # Apply algorithm (ensure the function is defined in your environment)\n",
    "        img_proc = apply_hungry_blue(img_orig, k) \n",
    "\n",
    "        # Compute absolute power\n",
    "        p_orig_mw = compute_power(img_orig)*1000  # convert to mW\n",
    "        p_proc_mw = compute_power(img_proc)*1000  # convert to mW\n",
    "        p_saved_mw = p_orig_mw - p_proc_mw\n",
    "\n",
    "        # Left data label: add absolute power comparison\n",
    "        ax_label = axes[row, 0]\n",
    "        label_str = (f\"{label} (Img #{idx})\\n\"\n",
    "                     f\"────────────\\n\"\n",
    "                     f\"Orig Pwr: {p_orig_mw:.1f} mW\\n\"\n",
    "                     f\"Saved: {p_saved_mw:.1f} mW\\n\"\n",
    "                     f\"────────────\\n\"\n",
    "                     f\"Sv Ratio: {stat['saving']:.1f}%\\n\"\n",
    "                     f\"Dst: {stat['dist']:.2f}%\")\n",
    "        \n",
    "        # Shift text left slightly to avoid overlapping with images\n",
    "        ax_label.text(-0.55, 0.5, label_str, transform=ax_label.transAxes, \n",
    "                      fontsize=13, fontweight='bold', color=color_code, ha='center', va='center',\n",
    "                      bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=5))\n",
    "\n",
    "        # 1. Original image\n",
    "        axes[row, 0].imshow(img_orig)\n",
    "        axes[row, 0].axis('off')\n",
    "\n",
    "        # 2. Processed image\n",
    "        axes[row, 1].imshow(img_proc)\n",
    "        axes[row, 1].axis('off')\n",
    "\n",
    "        # 3. Power ratio bar chart \n",
    "        ax_bar = axes[row, 2]\n",
    "        orig_means = [img_orig[:,:,0].mean(), img_orig[:,:,1].mean(), img_orig[:,:,2].mean()]\n",
    "        proc_means = [img_proc[:,:,0].mean(), img_proc[:,:,1].mean(), img_proc[:,:,2].mean()]\n",
    "        \n",
    "        x = np.arange(3)\n",
    "        width = 0.35\n",
    "        ax_bar.bar(x - width/2, orig_means, width, label='Orig', color=['#ff9999', '#99ff99', '#9999ff'], edgecolor='black')\n",
    "        ax_bar.bar(x + width/2, proc_means, width, label='Proc', color=['red', 'green', 'blue'], edgecolor='black')\n",
    "        \n",
    "        ax_bar.set_xticks(x)\n",
    "        ax_bar.set_xticklabels(['Red', 'Green', 'Blue'], fontweight='bold', fontsize=12)\n",
    "        ax_bar.legend(loc='upper right', fontsize=10)\n",
    "        ax_bar.grid(axis='y', alpha=0.3)\n",
    "        ax_bar.set_ylabel('Mean Pixel Value (Power Proxy)', fontsize=12)\n",
    "        ax_bar.set_ylim(0, max(max(orig_means), max(proc_means)) * 1.2)\n",
    "\n",
    "    plt.subplots_adjust(left=0.18, right=0.95, wspace=0.15, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Example call:\n",
    "if 120 in detailed_data:\n",
    "    plot_simplified_analysis(120, detailed_data[120], images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_saving_analysis(k, stats, images):\n",
    "    \"\"\"\n",
    "    Visualize energy saving analysis: fix text alignment, adapt to different aspect ratios\n",
    "    \"\"\"\n",
    "    valid_stats = [s for s in stats if s['idx'] < len(all_images)]\n",
    "    if not valid_stats:\n",
    "        print(\"Error: data mismatch\")\n",
    "        return\n",
    "\n",
    "    # Select extreme values of energy saving rate\n",
    "    min_stat = min(valid_stats, key=lambda x: x['saving'])\n",
    "    max_stat = max(valid_stats, key=lambda x: x['saving'])\n",
    "    cases = [('MIN Power Saving', min_stat, '#d62728'), \n",
    "             ('MAX Power Saving', max_stat, '#1f77b4')]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(22, 12))\n",
    "    fig.suptitle(f'Hungry Blue Power Saving Analysis: k = {k}', fontsize=26, fontweight='bold', y=0.98)\n",
    "\n",
    "    col_titles = ['Original Image', 'Processed (−B)', 'Power Contrib (RGB Mean)']\n",
    "    for ci, ct in enumerate(col_titles):\n",
    "        axes[0, ci].set_title(ct, fontsize=18, fontweight='bold', pad=25)\n",
    "\n",
    "    for row, (label, stat, color_code) in enumerate(cases):\n",
    "        idx = stat['idx']\n",
    "        img_orig = all_images[idx]\n",
    "        # Note: assumes apply_hungry_blue is defined externally\n",
    "        img_proc = apply_hungry_blue(img_orig, k) \n",
    "\n",
    "        # Compute absolute power data\n",
    "        p_orig_mw = compute_power(img_orig)*1000  # convert to mW\n",
    "        p_proc_mw = compute_power(img_proc)*1000  # convert to mW\n",
    "        p_saved_mw = p_orig_mw - p_proc_mw\n",
    "\n",
    "        # Annotate text info (use monospace font to align numbers)\n",
    "        label_str = (f\" {label}\\n\"\n",
    "                     f\" (Img #{idx})\\n\"\n",
    "                     f\" ────────────\\n\"\n",
    "                     f\" Orig Pwr: {p_orig_mw:>7.1f} mW\\n\"\n",
    "                     f\" Saved:    {p_saved_mw:>7.1f} mW\\n\"\n",
    "                     f\" ────────────\\n\"\n",
    "                     f\" Sv Ratio: {stat['saving']:>7.1f}%\\n\"\n",
    "                     f\" Dst:      {stat['dist']:>7.2f}%\")\n",
    "        \n",
    "        # ==================== [Key: use Figure coordinates for alignment] ====================\n",
    "        ax_label = axes[row, 0]\n",
    "        # Get subplot position on canvas, compute vertical center\n",
    "        pos = ax_label.get_position()\n",
    "        v_center = (pos.y0 + pos.y1) / 2\n",
    "        \n",
    "        # Use fig.text to lock x=0.03 (leftmost 3% of canvas)\n",
    "        # family='monospace' ensures numbers align vertically\n",
    "        fig.text(0.03, v_center, label_str, \n",
    "                 fontsize=15, fontweight='bold', color=color_code, \n",
    "                 family='monospace',\n",
    "                 ha='left', va='center', linespacing=1.8,\n",
    "                 bbox=dict(facecolor='white', alpha=0.95, edgecolor=color_code, lw=2.5, pad=15))\n",
    "\n",
    "        # Draw original and processed images\n",
    "        axes[row, 0].imshow(img_orig)\n",
    "        axes[row, 0].axis('off')\n",
    "        axes[row, 1].imshow(img_proc)\n",
    "        axes[row, 1].axis('off')\n",
    "\n",
    "        # Draw RGB channel mean bar chart\n",
    "        ax_bar = axes[row, 2]\n",
    "        orig_means = [img_orig[:,:,i].mean() for i in range(3)]\n",
    "        proc_means = [img_proc[:,:,i].mean() for i in range(3)]\n",
    "        \n",
    "        x_indices = np.arange(3)\n",
    "        width = 0.35\n",
    "        ax_bar.bar(x_indices - width/2, orig_means, width, label='Orig', color=['#ff9999', '#99ff99', '#9999ff'], edgecolor='black', alpha=0.7)\n",
    "        ax_bar.bar(x_indices + width/2, proc_means, width, label='Proc', color=['red', 'green', 'blue'], edgecolor='black')\n",
    "        \n",
    "        ax_bar.set_xticks(x_indices)\n",
    "        ax_bar.set_xticklabels(['Red', 'Green', 'Blue'], fontweight='bold', fontsize=13)\n",
    "        ax_bar.set_ylabel('Mean Pixel Value (Power Proxy)', fontsize=12)\n",
    "        ax_bar.grid(axis='y', alpha=0.3)\n",
    "        ax_bar.set_ylim(0, max(orig_means) * 1.3)\n",
    "        ax_bar.legend(loc='upper right', fontsize=11)\n",
    "\n",
    "    plt.subplots_adjust(left=0.23, right=0.96, wspace=0.35, hspace=0.4)\n",
    "    plt.show()\n",
    "\n",
    "# Example call\n",
    "if 120 in detailed_data:\n",
    "    plot_saving_analysis(120, detailed_data[120], images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_contrast_brightness(img, scale_v):\n",
    "    # Convert to HSV (skimage returns 0-1 float)\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] = hsv[:, :, 2] * scale_v # adjust V channel\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 1) # clip to 0-1\n",
    "    # Convert back to RGB and scale to 0-255\n",
    "    return (color.hsv2rgb(hsv) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy 2: Brightness Scaling \n",
    "#table 50 natural images or total images\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Store averages for Pareto curve\n",
    "results_contrast = []\n",
    "# Store detailed data for statistics table and representative images\n",
    "detailed_data_contrast = {}\n",
    "\n",
    "c_values = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1] \n",
    "\n",
    "print(\"Running Strategy 2: Brightness Scaling (detailed stats)...\")\n",
    "\n",
    "for c in c_values:\n",
    "    current_c_stats = []\n",
    "    \n",
    "    for idx, img in enumerate(all_images):\n",
    "        p_orig = estimate_power_part1(img)\n",
    "        img_new = apply_contrast_brightness(img, c)\n",
    "        p_new = estimate_power_part1(img_new)\n",
    "        \n",
    "        if p_orig > 0:\n",
    "            saving = (p_orig - p_new) / p_orig * 100\n",
    "        else:\n",
    "            saving = 0\n",
    "            \n",
    "        dist = compute_distortion(img, img_new)\n",
    "        \n",
    "        # Save single image result\n",
    "        current_c_stats.append({\n",
    "            \"idx\": idx,\n",
    "            \"saving\": saving,\n",
    "            \"dist\": dist\n",
    "        })\n",
    "        \n",
    "    # Compute averages (for plotting)\n",
    "    all_savings = [x['saving'] for x in current_c_stats]\n",
    "    all_dists = [x['dist'] for x in current_c_stats]\n",
    "    \n",
    "    results_contrast.append((np.mean(all_dists), np.mean(all_savings)))\n",
    "    \n",
    "    # Save detailed data to dict\n",
    "    detailed_data_contrast[c] = current_c_stats\n",
    "\n",
    "print(\"Strategy 2 computation done!\")\n",
    "\n",
    "# --- Show Strategy 2 statistics table ---\n",
    "stats_list_cont = []\n",
    "for c, stats in detailed_data_contrast.items():\n",
    "    savings = [s['saving'] for s in stats]\n",
    "    dists = [s['dist'] for s in stats]\n",
    "    stats_list_cont.append({\n",
    "        \"Parameter (c)\": c,\n",
    "        \"Avg Saving %\": np.mean(savings),\n",
    "        \"Min Saving %\": np.min(savings), # Min (as required)\n",
    "        \"Max Saving %\": np.max(savings), # Max (as required)\n",
    "        \"Avg Distortion\": np.mean(dists),\n",
    "        \"Min Distortion\": np.min(dists),\n",
    "        \"Max Distortion\": np.max(dists)\n",
    "    })\n",
    "\n",
    "print(\"\\n--- Summary Table for Brightness Scaling ---\")\n",
    "display(pd.DataFrame(stats_list_cont).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cont = [r[0] for r in results_contrast]\n",
    "y_cont = [r[1] for r in results_contrast]\n",
    "plt.plot(x_cont, y_cont, 'g-s', label='Brightness Scaling (Reduce V)')\n",
    "for x, y, c in zip(x_cont, y_cont, c_values):\n",
    "    if x < 10:\n",
    "        # y+0.5 places text slightly above the point\n",
    "        plt.text(x + 0.1, y + 0.5, f'c={c:.1f}', color='green', fontsize=9)\n",
    "plt.title('Pareto Curve: Power Saving vs. Image Distortion')\n",
    "plt.xlabel('Average Distortion (%)')\n",
    "plt.ylabel('Average Power Saving (%)')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.xlim(0, 11) \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "c_vals = [r['Parameter (c)'] for r in stats_list_cont]\n",
    "avg_savings = [r['Avg Saving %'] for r in stats_list_cont]\n",
    "avg_dists = [r['Avg Distortion'] for r in stats_list_cont]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: c vs Saving (reveals Gamma effect)\n",
    "ax1.plot(c_vals, avg_savings, 'ro-', label='Saving')\n",
    "ax1.set_xlabel('Parameter c (Brightness Factor)')\n",
    "ax1.set_ylabel('Average Power Saving (%)')\n",
    "ax1.set_title('c vs. Power Saving\\n')\n",
    "ax1.invert_xaxis() # display c from 1.0 to 0.1\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Plot 2: c vs Distortion (reveals Lab space nonlinearity)\n",
    "ax2.plot(c_vals, avg_dists, 'bo-', label='Distortion')\n",
    "ax2.set_xlabel('Parameter c (Brightness Factor)')\n",
    "ax2.set_ylabel('Average Distortion (%)')\n",
    "ax2.set_title('c vs. Distortion\\n')\n",
    "ax2.invert_xaxis()\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_set_energy_breakdown(target_c, group_indices, images):\n",
    "    \"\"\"\n",
    "    Analyze energy breakdown for all 50 images, sorted by distortion\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for idx in group_indices:\n",
    "        orig = images[idx]\n",
    "        proc = apply_contrast_brightness(orig, target_c)\n",
    "        lab_o, lab_p = color.rgb2lab(orig), color.rgb2lab(proc)\n",
    "        \n",
    "        diff_sq = (lab_o - lab_p)**2\n",
    "        msd_l, msd_a, msd_b = np.mean(diff_sq[:,:,0]), np.mean(diff_sq[:,:,1]), np.mean(diff_sq[:,:,2])\n",
    "        total_msd = msd_l + msd_a + msd_b\n",
    "        \n",
    "        results.append({\n",
    "            'idx': idx,\n",
    "            'total_dist': np.sqrt(total_msd),\n",
    "            'l_pct': msd_l / total_msd * 100,\n",
    "            'a_pct': msd_a / total_msd * 100,\n",
    "            'b_pct': msd_b / total_msd * 100\n",
    "        })\n",
    "\n",
    "    # Sort by total distortion descending to see the trend\n",
    "    results_sorted = sorted(results, key=lambda x: x['total_dist'], reverse=True)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    indices = np.arange(len(results_sorted))\n",
    "    l_vals = [r['l_pct'] for r in results_sorted]\n",
    "    a_vals = [r['a_pct'] for r in results_sorted]\n",
    "    b_vals = [r['b_pct'] for r in results_sorted]\n",
    "    \n",
    "    plt.bar(indices, l_vals, color='gold', label='$\\Delta L^2$ (Brightness)')\n",
    "    plt.bar(indices, a_vals, bottom=l_vals, color='green', label='$\\Delta a^2$ (Chroma-a)')\n",
    "    plt.bar(indices, b_vals, bottom=np.array(l_vals)+np.array(a_vals), color='blue', label='$\\Delta b^2$ (Chroma-b)')\n",
    "\n",
    "    plt.title(f\"Energy Contribution Across All 50 Natural Images C=0.7\", fontsize=15)\n",
    "    plt.xlabel(\"Images (Sorted from High Distortion to Low Distortion)\", fontsize=12)\n",
    "    plt.ylabel(\"Contribution (%)\", fontsize=12)\n",
    "    plt.xticks(indices, [r['idx'] for r in results_sorted], rotation=90, fontsize=8)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "    plt.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execute\n",
    "plot_full_set_energy_breakdown(0.7, range(0, 50), all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "\n",
    "def pad_image_to_center(img, target_h, target_w, bg_color=(1, 1, 1)):\n",
    "    \"\"\"\n",
    "    Helper: pad image to target size (target_h, target_w),\n",
    "    center the original, fill background with bg_color (default white).\n",
    "    \"\"\"\n",
    "    h, w, c = img.shape\n",
    "    \n",
    "    # Create solid color background canvas\n",
    "    # Assumes input is 0-1 float; adjust if 0-255 uint8\n",
    "    if img.dtype == np.uint8:\n",
    "        bg_val = [int(c * 255) for c in bg_color]\n",
    "        canvas = np.full((target_h, target_w, c), bg_val, dtype=np.uint8)\n",
    "    else:\n",
    "        canvas = np.full((target_h, target_w, c), bg_color, dtype=np.float64)\n",
    "    \n",
    "    # Compute center position\n",
    "    y_off = (target_h - h) // 2\n",
    "    x_off = (target_w - w) // 2\n",
    "    \n",
    "    # Place original image\n",
    "    canvas[y_off:y_off+h, x_off:x_off+w, :] = img\n",
    "    return canvas\n",
    "\n",
    "def analyze_distortion_aligned(target_c, group_indices):\n",
    "    \"\"\"\n",
    "    Alignment-optimized version:\n",
    "    1. Compute Max/Min data.\n",
    "    2. Pad images to the same size for alignment.\n",
    "    3. Display detailed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Data selection and preparation ---\n",
    "    all_stats = detailed_data_contrast[target_c]\n",
    "    group_stats = [item for item in all_stats if item['idx'] in group_indices]\n",
    "    \n",
    "    if not group_stats: return\n",
    "\n",
    "    # Find Max and Min\n",
    "    max_item = sorted(group_stats, key=lambda x: x['dist'], reverse=True)[0]\n",
    "    min_item = sorted(group_stats, key=lambda x: x['dist'], reverse=False)[0]\n",
    "    \n",
    "    cases = [\n",
    "        (\"MAX Distortion (Worst)\", max_item, '#7b241c'), \n",
    "        (\"MIN Distortion (Best)\",  min_item, '#1b4f72') \n",
    "    ]\n",
    "    \n",
    "    # --- 2. Preprocessing: unify image size for alignment ---\n",
    "    # Extract images first\n",
    "    imgs_data = []\n",
    "    for _, item, _ in cases:\n",
    "        idx = item['idx']\n",
    "        orig = all_images[idx] # original image\n",
    "        # Note: assumes apply_contrast_brightness returns the same size as original\n",
    "        proc = apply_contrast_brightness(orig, target_c) \n",
    "        imgs_data.append({'orig': orig, 'proc': proc, 'idx': idx})\n",
    "\n",
    "    # Compute max width and height\n",
    "    max_h = max(d['orig'].shape[0] for d in imgs_data)\n",
    "    max_w = max(d['orig'].shape[1] for d in imgs_data)\n",
    "\n",
    "    # --- 3. Plot initialization ---\n",
    "    # Use width_ratios to control column width: images 1 share, text box 1.2\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12), \n",
    "                             gridspec_kw={'width_ratios': [1, 1, 1.2]})\n",
    "    \n",
    "    fig.suptitle(f\"MAX and MIN distortion images| c={target_c}\", \n",
    "                 fontsize=20, fontweight='bold', y=0.96)\n",
    "\n",
    "    for row_idx, (title_prefix, item, theme_color) in enumerate(cases):\n",
    "        # Retrieve the prepared data\n",
    "        current_data = imgs_data[row_idx]\n",
    "        orig_raw = current_data['orig']\n",
    "        proc_raw = current_data['proc']\n",
    "        img_idx = current_data['idx']\n",
    "        distortion_val = item['dist']\n",
    "\n",
    "        # --- A. Core data computation (use raw original image, not padded) ---\n",
    "        # 1. RGB\n",
    "        avg_rgb_255 = np.mean(orig_raw, axis=(0, 1))\n",
    "        r, g, b = avg_rgb_255 / 255.0\n",
    "        \n",
    "        # 2. Lab\n",
    "        lab_orig = color.rgb2lab(orig_raw)\n",
    "        l_o, a_o, b_o = np.mean(lab_orig, axis=(0, 1))\n",
    "        \n",
    "        lab_proc = color.rgb2lab(proc_raw)\n",
    "        l_p, a_p, b_p = np.mean(lab_proc, axis=(0, 1))\n",
    "        \n",
    "        delta_L = l_p - l_o\n",
    "\n",
    "        # --- B. Visual alignment (Padding) ---\n",
    "        # Pad image to max_h, max_w with white background to blend with canvas\n",
    "        orig_display = pad_image_to_center(orig_raw, max_h, max_w, bg_color=(1,1,1))\n",
    "        proc_display = pad_image_to_center(proc_raw, max_h, max_w, bg_color=(1,1,1))\n",
    "\n",
    "        # --- C. Plotting ---\n",
    "        \n",
    "        # [Column 1] Original\n",
    "        ax_orig = axes[row_idx, 0]\n",
    "        ax_orig.imshow(orig_display)\n",
    "        ax_orig.set_title(f\"Original | ID: {img_idx}\", fontsize=14, fontweight='bold')\n",
    "        ax_orig.axis('off')\n",
    "        \n",
    "        # [Column 2] Processed\n",
    "        ax_proc = axes[row_idx, 1]\n",
    "        ax_proc.imshow(proc_display)\n",
    "        ax_proc.set_title(f\"Processed (c={target_c})\", fontsize=14, fontweight='bold', color=theme_color)\n",
    "        ax_proc.axis('off')\n",
    "        \n",
    "        # [Column 3] Info Board\n",
    "        ax_text = axes[row_idx, 2]\n",
    "        ax_text.axis('off')\n",
    "        \n",
    "        info_text = (\n",
    "            f\"CASE: {title_prefix}\\n\"\n",
    "            f\"Distortion: {distortion_val:.4f}\\n\"\n",
    "            f\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\"\n",
    "            f\"[1] Original RGB (Normalized):\\n\"\n",
    "            f\"    R={r:.3f}  G={g:.3f}  B={b:.3f}\\n\\n\"\n",
    "            \n",
    "            f\"[2] Lab Statistics (Avg):\\n\"\n",
    "            f\"    Orig: L={l_o:.1f}  (a={a_o:.1f}, b={b_o:.1f})\\n\"\n",
    "            f\"    Proc: L={l_p:.1f}  (a={a_p:.1f}, b={b_p:.1f})\\n\\n\"\n",
    "            \n",
    "            f\"[3] Lightness Shift (ΔL):\\n\"\n",
    "            f\"    ΔL = {delta_L:+.2f} ({'Brighter' if delta_L>0 else 'Darker'})\"\n",
    "        )\n",
    "        \n",
    "        # Vertically center the text box (valign='center')\n",
    "        ax_text.text(0.05, 0.5, info_text, transform=ax_text.transAxes, \n",
    "                     fontsize=13, family='monospace', verticalalignment='center',\n",
    "                     bbox=dict(boxstyle='round,pad=0.8', facecolor='#fdfdfd', \n",
    "                               edgecolor=theme_color, linewidth=2))\n",
    "\n",
    "    # Adjust subplot spacing\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "    # Slightly increase row spacing to avoid crowding\n",
    "    plt.subplots_adjust(hspace=0.15, wspace=0.05)\n",
    "    plt.show()\n",
    "\n",
    "# --- Execute ---\n",
    "TARGET_C = 0.7\n",
    "NATURAL_INDICES = range(0, len(all_images))\n",
    "\n",
    "print(f\"Generating aligned combined analysis plot (Target c={TARGET_C})...\")\n",
    "analyze_distortion_aligned(TARGET_C, NATURAL_INDICES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy: Pure Histogram Equalization (No Alpha)\n",
    "# Strategy: Pure Histogram Equalization (No Alpha)\n",
    "from skimage import color, exposure\n",
    "import numpy as np\n",
    "\n",
    "print(\"Running Standard Histogram Equalization (Baseline)...\")\n",
    "\n",
    "# Store results\n",
    "results_pure_hist = []\n",
    "\n",
    "for idx, img in enumerate(images):\n",
    "    # 1. Compute original power\n",
    "    p_orig = estimate_power_part1(img)\n",
    "    \n",
    "    # 2. Convert to HSV space\n",
    "    # skimage.color.rgb2hsv converts image to float64 (range 0-1)\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    \n",
    "    # 3. Apply histogram equalization to V channel (brightness)\n",
    "    # exposure.equalize_hist output is also float64 (range 0-1)\n",
    "    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    \n",
    "    # 4. Convert back to RGB and restore to 0-255 (uint8)\n",
    "    img_eq = (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "    \n",
    "    # 5. Compute new power\n",
    "    p_new = estimate_power_part1(img_eq)\n",
    "    \n",
    "    # 6. Compute metrics\n",
    "    if p_orig > 0:\n",
    "        saving = (p_orig - p_new) / p_orig * 100\n",
    "    else:\n",
    "        saving = 0\n",
    "        \n",
    "    dist = compute_distortion(img, img_eq)\n",
    "    \n",
    "    results_pure_hist.append({\n",
    "        \"image_idx\": idx,\n",
    "        \"saving\": saving,\n",
    "        \"dist\": dist\n",
    "    })\n",
    "\n",
    "# --- Summary statistics ---\n",
    "savings = [r['saving'] for r in results_pure_hist]\n",
    "dists = [r['dist'] for r in results_pure_hist]\n",
    "\n",
    "print(\"\\n--- Summary: Standard Histogram Equalization ---\")\n",
    "print(\"Power Saving Statistics:\")\n",
    "print(f\"  Average: {np.mean(savings):.2f}%\")\n",
    "print(f\"  Min:     {np.min(savings):.2f}% (negative means power increase)\")\n",
    "print(f\"  Max:     {np.max(savings):.2f}%\")  # added\n",
    "\n",
    "print(\"\\nDistortion Statistics:\")\n",
    "print(f\"  Average: {np.mean(dists):.2f}%\")\n",
    "print(f\"  Min:     {np.min(dists):.2f}%\")    # added\n",
    "print(f\"  Max:     {np.max(dists):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze baseline (Part 1: Pure Histogram Equalization Results)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assumes results_pure_hist was computed in a previous cell\n",
    "# results_pure_hist = [{'image_idx': 0, 'saving': 1.2, 'dist': 2.5}, ...]\n",
    "\n",
    "# 1. Find indices of key images\n",
    "# Sort by saving (Saving %)\n",
    "sorted_by_saving = sorted(results_pure_hist, key=lambda x: x['saving'])\n",
    "min_saving_idx = sorted_by_saving[0]['image_idx']      # Most power increase (Worst Case)\n",
    "max_saving_idx = sorted_by_saving[-1]['image_idx']     # Most power saving (Best Case)\n",
    "\n",
    "# Sort by distortion (Distortion %)\n",
    "sorted_by_dist = sorted(results_pure_hist, key=lambda x: x['dist'])\n",
    "min_dist_idx = sorted_by_dist[0]['image_idx']          # Min distortion (Min Distortion) - NEW!\n",
    "max_dist_idx = sorted_by_dist[-1]['image_idx']         # Max distortion (Max Distortion)\n",
    "\n",
    "# Print key indices and values\n",
    "print(f\"Min Saving Image Index: {min_saving_idx} (Saving: {sorted_by_saving[0]['saving']:.2f}%)\")\n",
    "print(f\"Max Saving Image Index: {max_saving_idx} (Saving: {sorted_by_saving[-1]['saving']:.2f}%)\")\n",
    "print(f\"Min Distortion Image Index: {min_dist_idx} (Dist: {sorted_by_dist[0]['dist']:.2f}%)\") # NEW!\n",
    "print(f\"Max Distortion Image Index: {max_dist_idx} (Dist: {sorted_by_dist[-1]['dist']:.2f}%)\")\n",
    "\n",
    "# 2. Define plot function (including image and histogram)\n",
    "def plot_comparison(idx, title_prefix):\n",
    "    img_orig = images[idx]\n",
    "    \n",
    "    # Redo transformation (to get the processed image)\n",
    "    hsv = color.rgb2hsv(img_orig)\n",
    "    # Apply histogram equalization to V channel (brightness)\n",
    "    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    img_trans = (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Compute specific values for this image\n",
    "    p_orig = estimate_power_part1(img_orig)\n",
    "    p_new = estimate_power_part1(img_trans)\n",
    "    saving = (p_orig - p_new) / p_orig * 100 if p_orig > 0 else 0\n",
    "    dist = compute_distortion(img_orig, img_trans)\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(f\"{title_prefix} (Image {idx})\\nSaving: {saving:.2f}%, Distortion: {dist:.2f}%\", fontsize=14)\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(img_orig)\n",
    "    axes[0, 0].set_title(\"Original Image\")\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Transformed image\n",
    "    axes[0, 1].imshow(img_trans)\n",
    "    axes[0, 1].set_title(\"Equalized Image\")\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Original image histogram (RGB)\n",
    "    axes[1, 0].set_title(\"Original Histogram (Pixel Distribution)\")\n",
    "    for i, col in enumerate(['r', 'g', 'b']):\n",
    "        hist, bins = np.histogram(img_orig[:, :, i], bins=256, range=(0, 256))\n",
    "        axes[1, 0].plot(bins[:-1], hist, color=col, alpha=0.7)\n",
    "    axes[1, 0].set_xlim([0, 256])\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Transformed histogram (RGB)\n",
    "    axes[1, 1].set_title(\"Equalized Histogram (Pixel Distribution)\")\n",
    "    for i, col in enumerate(['r', 'g', 'b']):\n",
    "        hist, bins = np.histogram(img_trans[:, :, i], bins=256, range=(0, 256))\n",
    "        axes[1, 1].plot(bins[:-1], hist, color=col, alpha=0.7)\n",
    "    axes[1, 1].set_xlim([0, 256])\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Execute plotting\n",
    "print(\"\\n--- Case 1: Worst Power Saving (Increased Power) ---\")\n",
    "plot_comparison(min_saving_idx, \"Worst Case Power Saving\")\n",
    "\n",
    "print(\"\\n--- Case 2: Best Power Saving ---\")\n",
    "plot_comparison(max_saving_idx, \"Best Case Power Saving\")\n",
    "\n",
    "print(\"\\n--- Case 3: Min Distortion (Subtle Change) ---\") # NEW!\n",
    "plot_comparison(min_dist_idx, \"Best Case Distortion (Min)\")\n",
    "\n",
    "print(\"\\n--- Case 4: Max Distortion ---\")\n",
    "plot_comparison(max_dist_idx, \"Worst Case Distortion (Max)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 3: Weighted Histogram Equalization\n",
    "from skimage import color, exposure\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assumes estimate_power_part1 and compute_distortion are already defined\n",
    "# Assumes images is your image list\n",
    "\n",
    "results_hist = []\n",
    "detailed_data_hist = {}\n",
    "\n",
    "# Alpha represents \"weight of equalized image\". 0=original, 1=full equalization\n",
    "alphas = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "print(\"Running Strategy 3: Histogram Equalization (optimized)...\")\n",
    "\n",
    "# For convenience, transpose data structure: group by alpha\n",
    "alpha_stats_storage = {a: [] for a in alphas}\n",
    "\n",
    "for idx, img in enumerate(images):\n",
    "    # 1. Base power\n",
    "    p_orig = estimate_power_part1(img)\n",
    "    \n",
    "    # 2. [Optimization] compute full equalized image once outside the loop (img_eq)\n",
    "    # Convert to HSV\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    # Equalize V channel (hsv[:, :, 2])\n",
    "    # Note: exposure.equalize_hist returns float 0-1\n",
    "    hsv_eq = hsv.copy()\n",
    "    hsv_eq[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    # Convert back to RGB and restore to 0-255 (uint8)\n",
    "    img_eq = (color.hsv2rgb(hsv_eq) * 255).astype(np.uint8)\n",
    "    \n",
    "    # 3. Iterate over Alpha for blending\n",
    "    for alpha in alphas:\n",
    "        if alpha == 0:\n",
    "            img_mixed = img\n",
    "        elif alpha == 1.0:\n",
    "            img_mixed = img_eq\n",
    "        else:\n",
    "            # Linear blend: (1-a)*original + a*equalized\n",
    "            # Must convert to float for computation, then back to uint8\n",
    "            img_mixed = (img.astype(float) * (1 - alpha) + img_eq.astype(float) * alpha)\n",
    "            img_mixed = np.clip(img_mixed, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Compute power and distortion\n",
    "        p_new = estimate_power_part1(img_mixed)\n",
    "        \n",
    "        if p_orig > 0:\n",
    "            saving = (p_orig - p_new) / p_orig * 100\n",
    "        else:\n",
    "            saving = 0\n",
    "            \n",
    "        dist = compute_distortion(img, img_mixed) # use LAB distance function defined earlier\n",
    "        \n",
    "        # Store in the list for the corresponding alpha\n",
    "        alpha_stats_storage[alpha].append({\n",
    "            \"image_idx\": idx,\n",
    "            \"saving\": saving,\n",
    "            \"dist\": dist\n",
    "        })\n",
    "\n",
    "print(\"Computation done! Summarizing data...\")\n",
    "\n",
    "# --- Summarize data for display and plotting ---\n",
    "stats_list_hist = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    stats = alpha_stats_storage[alpha]\n",
    "    \n",
    "    # Extract saving and dist for all images\n",
    "    savings = [s['saving'] for s in stats]\n",
    "    dists = [s['dist'] for s in stats]\n",
    "    \n",
    "    # Record averages for Pareto curve (Distortion, Saving)\n",
    "    mean_dist = np.mean(dists)\n",
    "    mean_saving = np.mean(savings)\n",
    "    results_hist.append((mean_dist, mean_saving))\n",
    "    \n",
    "    # Record detailed statistics table\n",
    "    stats_list_hist.append({\n",
    "        \"Alpha (Weight)\": alpha,\n",
    "        \"Avg Saving %\": mean_saving,\n",
    "        \"Min Saving %\": np.min(savings),\n",
    "        \"Max Saving %\": np.max(savings),\n",
    "        \"Avg Distortion %\": mean_dist,\n",
    "        \"Min Distortion %\": np.min(dists), # should be 0 (when alpha=0)\n",
    "        \"Max Distortion %\": np.max(dists)\n",
    "    })\n",
    "\n",
    "print(\"\\n--- Summary Table for Histogram Equalization ---\")\n",
    "df_hist = pd.DataFrame(stats_list_hist)\n",
    "display(df_hist.round(2))\n",
    "\n",
    "# Quickly plot Pareto points (if in Jupyter)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "x_val = [r[0] for r in results_hist]\n",
    "y_val = [r[1] for r in results_hist]\n",
    "plt.plot(x_val, y_val, marker='o', linestyle='-')\n",
    "plt.title(\"Pareto Curve: Histogram Equalization with alpha\")\n",
    "plt.xlabel(\"Average Distortion (%)\")\n",
    "plt.ylabel(\"Average Power Saving (%)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 4: Gamma Correction (Detailed Stats Version)\n",
    "from skimage import exposure, color\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "gammas = [1.0, 1.2, 1.4, 1.6, 1.8, 2.0]\n",
    "stats_list_gamma = []\n",
    "\n",
    "print(\"Running Detailed Gamma Correction Analysis...\")\n",
    "\n",
    "for gamma in gammas:\n",
    "    current_savings = []\n",
    "    current_dists = []\n",
    "    \n",
    "    for img in images:\n",
    "        p_orig = estimate_power_part1(img)\n",
    "        \n",
    "        # Gamma Transform\n",
    "        hsv = color.rgb2hsv(img)\n",
    "        hsv[:, :, 2] = exposure.adjust_gamma(hsv[:, :, 2], gamma=gamma)\n",
    "        img_gamma = (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "        \n",
    "        # Metrics\n",
    "        p_new = estimate_power_part1(img_gamma)\n",
    "        saving = (p_orig - p_new) / p_orig * 100 if p_orig > 0 else 0\n",
    "        dist = compute_distortion(img, img_gamma)\n",
    "        \n",
    "        current_savings.append(saving)\n",
    "        current_dists.append(dist)\n",
    "    \n",
    "    # Summary statistics\n",
    "    stats_list_gamma.append({\n",
    "        \"Gamma\": gamma,\n",
    "        \"Avg Saving\": np.mean(current_savings),\n",
    "        \"Min Saving\": np.min(current_savings),\n",
    "        \"Max Saving\": np.max(current_savings),\n",
    "        \"Avg Dist\": np.mean(current_dists),\n",
    "        \"Min Dist\": np.min(current_dists),\n",
    "        \"Max Dist\": np.max(current_dists)\n",
    "    })\n",
    "\n",
    "# Display DataFrame (can paste rows into LaTeX table)\n",
    "df_gamma = pd.DataFrame(stats_list_gamma)\n",
    "print(\"\\n--- Gamma Correction Detailed Statistics ---\")\n",
    "display(df_gamma.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import exposure, color\n",
    "\n",
    "# 1. Define the list of Gamma values to test\n",
    "# 1.2 and 1.6 were mentioned; add more points for a smoother curve\n",
    "gammas = [1.0, 1.2, 1.4, 1.6, 1.8, 2.0]\n",
    "\n",
    "# Store the final average result for each Gamma setting\n",
    "summary_results = []\n",
    "\n",
    "print(\"Starting Gamma correction strategy analysis...\")\n",
    "\n",
    "# --- Outer loop: iterate over different Gamma values ---\n",
    "for gamma in gammas:\n",
    "    \n",
    "    # Temp list for per-image data under current Gamma\n",
    "    current_savings = []\n",
    "    current_dists = []\n",
    "    \n",
    "    # --- Inner loop: iterate over each image ---\n",
    "    for img in images:\n",
    "        # A. Compute original power\n",
    "        p_orig = estimate_power_part1(img)\n",
    "        \n",
    "        # B. Apply Gamma transformation (core algorithm)\n",
    "        # Convert to HSV -> adjust V channel -> convert back to RGB\n",
    "        hsv = color.rgb2hsv(img)\n",
    "        hsv[:, :, 2] = exposure.adjust_gamma(hsv[:, :, 2], gamma=gamma)\n",
    "        img_new = (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "        \n",
    "        # C. Compute new metrics\n",
    "        p_new = estimate_power_part1(img_new)\n",
    "        \n",
    "        # Energy saving rate\n",
    "        if p_orig > 0:\n",
    "            saving = (p_orig - p_new) / p_orig * 100\n",
    "        else:\n",
    "            saving = 0\n",
    "            \n",
    "        # Distortion rate\n",
    "        dist = compute_distortion(img, img_new)\n",
    "        \n",
    "        # D. Collect data\n",
    "        current_savings.append(saving)\n",
    "        current_dists.append(dist)\n",
    "    \n",
    "    # --- Compute average performance for current Gamma ---\n",
    "    avg_saving = np.mean(current_savings)\n",
    "    avg_dist = np.mean(current_dists)\n",
    "    \n",
    "    # Save to summary list\n",
    "    summary_results.append({\n",
    "        \"Gamma\": gamma,\n",
    "        \"Avg Saving (%)\": avg_saving,\n",
    "        \"Avg Distortion (%)\": avg_dist\n",
    "    })\n",
    "    \n",
    "    print(f\"Done: Gamma = {gamma} -> Avg saving: {avg_saving:.2f}%, Avg distortion: {avg_dist:.2f}%\")\n",
    "\n",
    "# --- 2. Show data table ---\n",
    "df_summary = pd.DataFrame(summary_results)\n",
    "print(\"\\n--- Final summary table ---\")\n",
    "display(df_summary.round(2))\n",
    "\n",
    "# --- 3. Plot Pareto curve ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Extract X (distortion) and Y (saving)\n",
    "x_vals = df_summary[\"Avg Distortion (%)\"]\n",
    "y_vals = df_summary[\"Avg Saving (%)\"]\n",
    "labels = df_summary[\"Gamma\"]\n",
    "\n",
    "# Draw lines and points\n",
    "plt.plot(x_vals, y_vals, marker='o', linestyle='-', linewidth=2, color='tab:blue', label='Gamma Strategy')\n",
    "\n",
    "# Label each point with its Gamma value\n",
    "for i, txt in enumerate(labels):\n",
    "    plt.annotate(f\"γ={txt}\", \n",
    "                 (x_vals[i], y_vals[i]), \n",
    "                 textcoords=\"offset points\", \n",
    "                 xytext=(0,10), \n",
    "                 ha='center')\n",
    "\n",
    "# Decorate chart\n",
    "plt.xlabel(\"Average Distortion (%)\")\n",
    "plt.ylabel(\"Average Power Saving (%)\")\n",
    "plt.title(\"Pareto Curve: Gamma Correction Trade-off\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find extreme images for a specific gamma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import exposure, color\n",
    "\n",
    "# Assumes image list is called images and evaluation functions are defined\n",
    "target_gamma = 1.4\n",
    "image_details = []\n",
    "\n",
    "print(f\"Analyzing per-image data for Gamma = {target_gamma}...\")\n",
    "\n",
    "# Use enumerate to get the index (i) of each image\n",
    "for i, img in enumerate(images):\n",
    "    p_orig = estimate_power_part1(img)\n",
    "    \n",
    "    # Gamma Transform\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] = exposure.adjust_gamma(hsv[:, :, 2], gamma=target_gamma)\n",
    "    img_gamma = (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Metrics\n",
    "    p_new = estimate_power_part1(img_gamma)\n",
    "    saving = (p_orig - p_new) / p_orig * 100 if p_orig > 0 else 0\n",
    "    dist = compute_distortion(img, img_gamma)\n",
    "    \n",
    "    # Store the index and result for this image\n",
    "    image_details.append({\n",
    "        \"Image_Index\": i,  # use file_names[i] if you have a filename list\n",
    "        \"Saving\": saving,\n",
    "        \"Distortion\": dist\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easy extreme value lookup\n",
    "df_details = pd.DataFrame(image_details)\n",
    "\n",
    "# --- Core search logic ---\n",
    "# idxmax() and idxmin() return row index of max/min value in the column\n",
    "idx_max_dist = df_details['Distortion'].idxmax()\n",
    "idx_min_dist = df_details['Distortion'].idxmin()\n",
    "idx_max_saving = df_details['Saving'].idxmax()\n",
    "idx_min_saving = df_details['Saving'].idxmin()\n",
    "\n",
    "print(\"\\n--- Extreme image results (Gamma=1.4) ---\")\n",
    "print(f\"Max Distortion image index: {df_details.loc[idx_max_dist, 'Image_Index']}, distortion: {df_details.loc[idx_max_dist, 'Distortion']:.2f}\")\n",
    "print(f\"Min Distortion image index: {df_details.loc[idx_min_dist, 'Image_Index']}, distortion: {df_details.loc[idx_min_dist, 'Distortion']:.2f}\")\n",
    "print(f\"Max Saving image index: {df_details.loc[idx_max_saving, 'Image_Index']}, saving: {df_details.loc[idx_max_saving, 'Saving']:.2f}%\")\n",
    "print(f\"Min Saving image index: {df_details.loc[idx_min_saving, 'Image_Index']}, saving: {df_details.loc[idx_min_saving, 'Saving']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import color, exposure\n",
    "\n",
    "# --- 1. Helper Functions Definitions ---\n",
    "\n",
    "def apply_gamma_and_get_hsv(img_rgb, gamma_val):\n",
    "    \"\"\"Helper: Applies Gamma to V channel and returns processed RGB and both HSV arrays.\"\"\"\n",
    "    hsv_original = color.rgb2hsv(img_rgb)\n",
    "    hsv_processed = hsv_original.copy()\n",
    "    \n",
    "    # Apply Gamma to the V (Value) channel\n",
    "    hsv_processed[:, :, 2] = exposure.adjust_gamma(hsv_processed[:, :, 2], gamma=gamma_val)\n",
    "    \n",
    "    # Convert back to RGB for display (clip to 0-255 and cast to uint8)\n",
    "    img_processed = np.clip(color.hsv2rgb(hsv_processed) * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Return both original and processed HSV data for comparison\n",
    "    return img_processed, hsv_original, hsv_processed\n",
    "\n",
    "def plot_hsv_histogram(ax, hsv_data, title_text, highlight_v=True):\n",
    "    \"\"\"Helper: Plots HSV histograms. Emphasizes V channel if highlight_v is True.\"\"\"\n",
    "    labels = ['Hue', 'Saturation', 'Value (V)']\n",
    "    \n",
    "    # Emphasize V channel with bold black line\n",
    "    plot_styles = [\n",
    "        {'color': 'magenta', 'lw': 1, 'alpha': 0.5}, # Hue style\n",
    "        {'color': 'cyan', 'lw': 1, 'alpha': 0.5},    # Saturation style\n",
    "        {'color': 'black', 'lw': 2 if highlight_v else 1.5, 'alpha': 0.9 if highlight_v else 0.7} # Value style\n",
    "    ]\n",
    "\n",
    "    for i, style in enumerate(plot_styles):\n",
    "        hist, bins = np.histogram(hsv_data[:, :, i].flatten(), bins=100, range=[0.0, 1.0])\n",
    "        ax.plot(bins[:-1], hist, label=labels[i], **style)\n",
    "    \n",
    "    ax.set_title(title_text, fontsize=10)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_xlabel(\"Normalized Value (0.0-1.0)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- 2. Main Visualization Loop ---\n",
    "\n",
    "target_gamma = 1.4\n",
    "\n",
    "# Define the four extreme cases using the indices found previously\n",
    "# Make sure idx_max_dist, idx_min_dist, idx_max_saving, idx_min_saving are in memory\n",
    "cases_to_analyze = [\n",
    "    (\"Case 1: Max Distortion\", idx_max_dist),\n",
    "    (\"Case 2: Min Distortion\", idx_min_dist),\n",
    "    (\"Case 3: Max Saving\", idx_max_saving),\n",
    "    (\"Case 4: Min Saving\", idx_min_saving)\n",
    "]\n",
    "\n",
    "print(f\"Starting HSV comparison visualization for Gamma={target_gamma} extreme cases...\")\n",
    "\n",
    "for case_name, img_idx in cases_to_analyze:\n",
    "    # A. Prepare Data\n",
    "    img_orig = images[img_idx]\n",
    "    \n",
    "    # Now unpacking three variables instead of two\n",
    "    img_proc, hsv_orig, hsv_proc = apply_gamma_and_get_hsv(img_orig, target_gamma)\n",
    "    \n",
    "    # B. Re-calculate metrics specific to this image for the main title\n",
    "    p_orig_val = estimate_power_part1(img_orig)\n",
    "    p_new_val = estimate_power_part1(img_proc)\n",
    "    sav_val = (p_orig_val - p_new_val) / p_orig_val * 100 if p_orig_val > 0 else 0\n",
    "    dist_val = compute_distortion(img_orig, img_proc)\n",
    "\n",
    "    # C. Create Figure Canvas (1 row, 4 columns)\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    main_title = f\"{case_name} [Index: {img_idx}] - Saving: {sav_val:.2f}%, Dist: {dist_val:.2f}\"\n",
    "    fig.suptitle(main_title, fontsize=14, y=1.02)\n",
    "\n",
    "    # D. Plot Subplots\n",
    "    \n",
    "    # Subplot 1: Original Image\n",
    "    axes[0].imshow(img_orig)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Subplot 2: Original HSV Histogram\n",
    "    plot_hsv_histogram(axes[1], hsv_orig, \"Original HSV Distribution\", highlight_v=True)\n",
    "\n",
    "    # Subplot 3: Processed Image\n",
    "    axes[2].imshow(img_proc)\n",
    "    axes[2].set_title(f\"Processed (Gamma {target_gamma})\")\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    # Subplot 4: Processed HSV Histogram\n",
    "    plot_hsv_histogram(axes[3], hsv_proc, \"Processed HSV Distribution\", highlight_v=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L shift is large for the bird but almost unchanged for the bear, because converting HSV back to RGB also changes little, so the Lab difference between original and processed is small for the bear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure, color\n",
    "\n",
    "# 1. Define parameter ranges uniformly (adjust as needed)\n",
    "k_values = list(range(0, 256, 10))\n",
    "c_values = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "alphas = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "# Extend Gamma range slightly to find the optimum near the 3% threshold\n",
    "gammas = [1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8, 3.0] \n",
    "\n",
    "# 2. Define unified test function\n",
    "def find_best_saving_under_limit(img_list, transform_func, params, strategy_name, dist_limit=3.0):\n",
    "    best_saving = 0\n",
    "    best_param = None\n",
    "    best_dist = 0\n",
    "    \n",
    "    print(f\"Scanning all parameters for {strategy_name}...\")\n",
    "    for p in params:\n",
    "        savings = []\n",
    "        dists = []\n",
    "        for img in img_list:\n",
    "            p_orig = estimate_power_part1(img)\n",
    "            img_new = transform_func(img, p)\n",
    "            p_new = estimate_power_part1(img_new)\n",
    "            \n",
    "            saving = (p_orig - p_new) / p_orig * 100 if p_orig > 0 else 0\n",
    "            dist = compute_distortion(img, img_new)\n",
    "            \n",
    "            savings.append(saving)\n",
    "            dists.append(dist)\n",
    "            \n",
    "        avg_saving = np.mean(savings)\n",
    "        avg_dist = np.mean(dists)\n",
    "        \n",
    "        # Core logic: distortion must be strictly below limit (3.0%)\n",
    "        if avg_dist < dist_limit:\n",
    "            # Among valid parameters, find the one with max saving\n",
    "            if avg_saving > best_saving:\n",
    "                best_saving = avg_saving\n",
    "                best_param = p\n",
    "                best_dist = avg_dist\n",
    "                \n",
    "    print(f\"  -> Best param: {best_param}, distortion: {best_dist:.2f}%, saving: {best_saving:.2f}%\")\n",
    "    return best_saving, best_param, best_dist\n",
    "\n",
    "# 3. Wrap transformation functions for each strategy (based on existing code)\n",
    "def wrapper_hungry_blue(img, k):\n",
    "    return apply_hungry_blue(img, k)\n",
    "\n",
    "def wrapper_brightness(img, c):\n",
    "    return apply_contrast_brightness(img, c)\n",
    "\n",
    "def wrapper_he(img, alpha):\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv_eq = hsv.copy()\n",
    "    hsv_eq[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    img_eq = (color.hsv2rgb(hsv_eq) * 255).astype(np.uint8)\n",
    "    img_mixed = (img.astype(float) * (1 - alpha) + img_eq.astype(float) * alpha)\n",
    "    return np.clip(img_mixed, 0, 255).astype(np.uint8)\n",
    "\n",
    "def wrapper_gamma(img, gamma):\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] = exposure.adjust_gamma(hsv[:, :, 2], gamma=gamma)\n",
    "    return (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "\n",
    "# 4. Run evaluation (on 50 natural images)\n",
    "print(\"=== Finding max Saving with Distortion < 3% ===\")\n",
    "DIST_LIMIT = 3.0\n",
    "dataset_to_test = images \n",
    "\n",
    "res_hb = find_best_saving_under_limit(dataset_to_test, wrapper_hungry_blue, k_values, \"Hungry Blue\", DIST_LIMIT)\n",
    "res_bs = find_best_saving_under_limit(dataset_to_test, wrapper_brightness, c_values, \"Brightness Scaling\", DIST_LIMIT)\n",
    "res_he = find_best_saving_under_limit(dataset_to_test, wrapper_he, alphas, \"Histogram Equalization\", DIST_LIMIT)\n",
    "res_gm = find_best_saving_under_limit(dataset_to_test, wrapper_gamma, gammas, \"Gamma Correction\", DIST_LIMIT)\n",
    "\n",
    "# 5. Visualize final bar comparison chart\n",
    "strategies = ['Hungry Blue', 'Brightness Scaling', 'Histogram Eq', 'Gamma Correction']\n",
    "best_savings = [res_hb[0], res_bs[0], res_he[0], res_gm[0]]\n",
    "best_params = [res_hb[1], res_bs[1], res_he[1], res_gm[1]]\n",
    "actual_dists = [res_hb[2], res_bs[2], res_he[2], res_gm[2]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(strategies, best_savings, color=['#3498db', '#2ecc71', '#e74c3c', '#9b59b6'], alpha=0.85, edgecolor='black')\n",
    "\n",
    "plt.title(f'Maximum Power Saving under Strict {DIST_LIMIT}% Distortion Limit', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Average Power Saving (%)', fontsize=12)\n",
    "\n",
    "# Reserve top space based on highest saving\n",
    "max_y = max(best_savings)\n",
    "plt.ylim(0, max_y + 10 if max_y > 0 else 10) \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add detailed data labels on bars\n",
    "for bar, param, dist in zip(bars, best_params, actual_dists):\n",
    "    height = bar.get_height()\n",
    "    \n",
    "    # Show saving percentage at top\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height:.2f}%', \n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold', color='black')\n",
    "             \n",
    "    # Show optimal parameter and actual distortion in the middle of bar\n",
    "    if height > 0:\n",
    "        info_text = f\"Param: {param}\\nDist: {dist:.2f}%\"\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height / 2,\n",
    "                 info_text, \n",
    "                 ha='center', va='center', fontsize=11, color='white', fontweight='bold',\n",
    "                 bbox=dict(facecolor='black', alpha=0.4, edgecolor='none', boxstyle='round,pad=0.3'))\n",
    "    else:\n",
    "        # If saving is 0 (e.g. HE cannot achieve it), label at bottom\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., 1, \"No Saving\", ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import exposure, color\n",
    "\n",
    "# ==========================================\n",
    "# 1. Define wrapper functions for 4 strategies\n",
    "# ==========================================\n",
    "\n",
    "def wrapper_hungry_blue(img, k):\n",
    "    img_mod = img.astype(np.int16)\n",
    "    img_mod[:, :, 2] = img_mod[:, :, 2] - k\n",
    "    return np.clip(img_mod, 0, 255).astype(np.uint8)\n",
    "\n",
    "def wrapper_brightness(img, c):\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] *= c\n",
    "    return (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "\n",
    "def wrapper_he(img, alpha):\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv_eq = hsv.copy()\n",
    "    hsv_eq[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    img_eq = (color.hsv2rgb(hsv_eq) * 255).astype(np.uint8)\n",
    "    img_mixed = (img.astype(float) * (1 - alpha) + img_eq.astype(float) * alpha)\n",
    "    return np.clip(img_mixed, 0, 255).astype(np.uint8)\n",
    "\n",
    "def wrapper_gamma(img, gamma):\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] = exposure.adjust_gamma(hsv[:, :, 2], gamma=gamma)\n",
    "    return (color.hsv2rgb(hsv) * 255).astype(np.uint8)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Configure parameters (optimized Hungry Blue range)\n",
    "# ==========================================\n",
    "strategies_config = {\n",
    "    \"Hungry Blue\": {\n",
    "        \"func\": wrapper_hungry_blue,\n",
    "        \"params\": range(0, 101, 20), # k: 0, 20, 40, 60, 80, 100 (narrower range, more comparable)\n",
    "        \"style\": {\"color\": \"tab:blue\", \"marker\": \"o\", \"linestyle\": \"-\"}\n",
    "    },\n",
    "    \"Brightness Scaling\": {\n",
    "        \"func\": wrapper_brightness,\n",
    "        \"params\": [1.0, 0.9, 0.8, 0.7, 0.6, 0.5], \n",
    "        \"style\": {\"color\": \"tab:green\", \"marker\": \"s\", \"linestyle\": \"--\"}\n",
    "    },\n",
    "    \"Gamma Correction\": {\n",
    "        \"func\": wrapper_gamma,\n",
    "        \"params\": [1.0, 1.2, 1.4, 1.6, 1.8, 2.0], \n",
    "        \"style\": {\"color\": \"tab:purple\", \"marker\": \"D\", \"linestyle\": \"-\"}\n",
    "    },\n",
    "    \"Histogram Eq (Mix)\": {\n",
    "        \"func\": wrapper_he,\n",
    "        \"params\": [0.0, 0.2, 0.4, 0.6, 0.8, 1.0], \n",
    "        \"style\": {\"color\": \"tab:red\", \"marker\": \"^\", \"linestyle\": \":\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 3. Compute data\n",
    "# ==========================================\n",
    "results_all = {}\n",
    "print(\"Computing comparison data for 4 core strategies (based on images list)...\")\n",
    "\n",
    "for name, config in strategies_config.items():\n",
    "    print(f\"Running {name}...\")\n",
    "    avg_dists = []\n",
    "    avg_savings = []\n",
    "    \n",
    "    for p in config[\"params\"]:\n",
    "        dists = []\n",
    "        savings = []\n",
    "        for img in images: # ensure 'images' list is loaded\n",
    "            p_orig = estimate_power_part1(img)\n",
    "            img_new = config[\"func\"](img, p)\n",
    "            p_new = estimate_power_part1(img_new)\n",
    "            \n",
    "            saving = (p_orig - p_new) / p_orig * 100 if p_orig > 0 else 0\n",
    "            dist = compute_distortion(img, img_new)\n",
    "            \n",
    "            savings.append(saving)\n",
    "            dists.append(dist)\n",
    "            \n",
    "        avg_dists.append(np.mean(dists))\n",
    "        avg_savings.append(np.mean(savings))\n",
    "        \n",
    "    results_all[name] = {\"x\": avg_dists, \"y\": avg_savings}\n",
    "\n",
    "# ==========================================\n",
    "# 4. Plot (with boundary check)\n",
    "# ==========================================\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Define visible range\n",
    "X_LIMIT = 8.0\n",
    "Y_LIMIT = 40.0\n",
    "\n",
    "for name, data in results_all.items():\n",
    "    style = strategies_config[name][\"style\"]\n",
    "    \n",
    "    # Draw lines and points\n",
    "    plt.plot(data[\"x\"], data[\"y\"], \n",
    "             label=name,\n",
    "             color=style[\"color\"],\n",
    "             marker=style[\"marker\"],\n",
    "             linestyle=style[\"linestyle\"],\n",
    "             linewidth=2, markersize=7, alpha=0.8)\n",
    "    \n",
    "    # Annotate key parameter points\n",
    "    params = strategies_config[name][\"params\"]\n",
    "    # Annotate points at index 1, 2, 3 (adjust based on param count)\n",
    "    indices_to_label = list(range(len(params))) \n",
    "    \n",
    "    if len(params) > max(indices_to_label):\n",
    "        for idx in indices_to_label:\n",
    "            x_pos = data[\"x\"][idx]\n",
    "            y_pos = data[\"y\"][idx]\n",
    "            p_val = params[idx]\n",
    "            \n",
    "            # [Key fix] only draw label if point is within X axis range\n",
    "            if x_pos <= X_LIMIT and y_pos <= Y_LIMIT:\n",
    "                p_str = f\"{p_val:.1f}\" if isinstance(p_val, float) else f\"{p_val}\"\n",
    "                \n",
    "                # Fine-tune position to avoid overlapping with point\n",
    "                plt.text(x_pos, y_pos + 0.8, \n",
    "                         p_str, \n",
    "                         fontsize=9, color=style[\"color\"], fontweight='bold', ha='center')\n",
    "\n",
    "# Add distortion constraint reference line\n",
    "plt.axvline(x=2.0, color='gray', linestyle='-', alpha=0.3, label='Limit 2%')\n",
    "plt.axvline(x=3.0, color='gray', linestyle='--', alpha=0.3, label='Limit 3%')\n",
    "\n",
    "plt.title('Pareto Curves: Comparison of Core Strategies', fontsize=14)\n",
    "plt.xlabel('Average Distortion (%)', fontsize=12)\n",
    "plt.ylabel('Average Power Saving (%)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend(fontsize=11, loc='upper left')\n",
    "\n",
    "# Set axis range\n",
    "plt.xlim(0, X_LIMIT)  \n",
    "plt.ylim(0, Y_LIMIT)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: modify loop logic to support grouped analysis\n",
    "results_natural = []\n",
    "results_screens = []\n",
    "\n",
    "for k in k_values:\n",
    "    nat_savings, nat_dists = [], []\n",
    "    scr_savings, scr_dists = [], []\n",
    "    \n",
    "    # Natural image group\n",
    "    for img in images:\n",
    "        p_orig = estimate_power_part1(img)\n",
    "        img_new = apply_hungry_blue(img, k)\n",
    "        p_new = estimate_power_part1(img_new)\n",
    "        nat_savings.append((p_orig - p_new) / p_orig * 100)\n",
    "        nat_dists.append(compute_distortion(img, img_new))\n",
    "        \n",
    "    # Screenshot group\n",
    "    for img in screen_images:\n",
    "        p_orig = estimate_power_part1(img)\n",
    "        img_new = apply_hungry_blue(img, k)\n",
    "        p_new = estimate_power_part1(img_new)\n",
    "        scr_savings.append((p_orig - p_new) / p_orig * 100)\n",
    "        scr_dists.append(compute_distortion(img, img_new))\n",
    "        \n",
    "    results_natural.append((np.mean(nat_dists), np.mean(nat_savings)))\n",
    "    results_screens.append((np.mean(scr_dists), np.mean(scr_savings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# Plot natural image group\n",
    "x_nat = [r[0] for r in results_natural]\n",
    "y_nat = [r[1] for r in results_natural]\n",
    "plt.plot(x_nat, y_nat, 'b-o', label='Natural Images (Average)')\n",
    "\n",
    "# Plot screenshot group\n",
    "x_scr = [r[0] for r in results_screens]\n",
    "y_scr = [r[1] for r in results_screens]\n",
    "plt.plot(x_scr, y_scr, 'r--s', label='Screenshots (Average)')\n",
    "\n",
    "plt.title('Pareto Frontier: Natural vs. Screenshots')\n",
    "plt.xlabel('Distortion (%)')\n",
    "plt.ylabel('Power Saving (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "img49 = images[49]\n",
    "p_orig = compute_power(img49)\n",
    "\n",
    "# Check actual pixel mean and power share for each channel\n",
    "r49, g49, b49 = img49[:,:,0].astype(np.float64), img49[:,:,1].astype(np.float64), img49[:,:,2].astype(np.float64)\n",
    "gamma_pow = 0.7755\n",
    "w_r, w_g, w_b = 2.13636845e-7, 1.77746705e-7, 2.14348309e-7\n",
    "\n",
    "p_r = w_r * np.sum(np.power(r49, gamma_pow))\n",
    "p_g = w_g * np.sum(np.power(g49, gamma_pow))\n",
    "p_b = w_b * np.sum(np.power(b49, gamma_pow))\n",
    "\n",
    "print(f\"=== Image 49 Channel Analysis ===\")\n",
    "print(f\"R: mean={r49.mean():.1f}, power share={p_r/p_orig*100:.1f}%\")\n",
    "print(f\"G: mean={g49.mean():.1f}, power share={p_g/p_orig*100:.1f}%\")\n",
    "print(f\"B: mean={b49.mean():.1f}, power share={p_b/p_orig*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Compare 3 strategies parameter by parameter\n",
    "rows = []\n",
    "for k in [0, 20, 40, 60, 80, 100]:\n",
    "    img_new = wrapper_hungry_blue(img49, k)\n",
    "    p_new = compute_power(img_new)\n",
    "    rows.append({\"Strategy\": \"Hungry Blue\", \"Param\": f\"k={k}\",\n",
    "                 \"Saving(%)\": round((p_orig-p_new)/p_orig*100, 3),\n",
    "                 \"Distortion(%)\": round(compute_distortion(img49, img_new), 3)})\n",
    "\n",
    "for c in [1.0, 0.9, 0.8, 0.7, 0.6, 0.5]:\n",
    "    img_new = wrapper_brightness(img49, c)\n",
    "    p_new = compute_power(img_new)\n",
    "    rows.append({\"Strategy\": \"Brightness\", \"Param\": f\"c={c}\",\n",
    "                 \"Saving(%)\": round((p_orig-p_new)/p_orig*100, 3),\n",
    "                 \"Distortion(%)\": round(compute_distortion(img49, img_new), 3)})\n",
    "\n",
    "for g in [1.0, 1.2, 1.4, 1.6, 1.8, 2.0]:\n",
    "    img_new = wrapper_gamma(img49, g)\n",
    "    p_new = compute_power(img_new)\n",
    "    rows.append({\"Strategy\": \"Gamma\", \"Param\": f\"γ={g}\",\n",
    "                 \"Saving(%)\": round((p_orig-p_new)/p_orig*100, 3),\n",
    "                 \"Distortion(%)\": round(compute_distortion(img49, img_new), 3)})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
